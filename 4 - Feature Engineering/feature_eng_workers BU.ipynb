{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import warnings\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, RandomizedSearchCV, cross_val_score)\n",
    "from sklearn.metrics import (r2_score, mean_squared_error, make_scorer)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, OneHotEncoder, LabelEncoder\n",
    ")\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Configure Notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_feature(data):\n",
    "    \n",
    "    feature_selected = ['tottr',\n",
    "                        'gender',\n",
    "                        'race',\n",
    "                        'age',\n",
    "                        'citizen',\n",
    "                        'incentive',\n",
    "                        'vehicle_count',\n",
    "                        'income',\n",
    "                        'worker_count',\n",
    "                        'is_workday',\n",
    "                        'workday_count',\n",
    "                        'driver_license',\n",
    "                        'job_count',\n",
    "                        'apparent_temperature_mean (Â°C)',\n",
    "                        'WMO_code']\n",
    "\n",
    "    selected_data = data[feature_selected]\n",
    "    \n",
    "    return selected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Assume df is your DataFrame and 'y' is the target column\n",
    "\n",
    "# Step 1: Split the data into train (70%) and temp (30%)\n",
    "train_df, temp_df = train_test_split(df_filtered, test_size=0.3, stratify=df_filtered['mode_category'], random_state=42)\n",
    "\n",
    "# Step 2: Split the temp set into validation (15%) and test (15%)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['mode_category'], random_state=42)\n",
    "\n",
    "# Step 3: Separate features (X) and target (y) for the training set\n",
    "X_train = selected_feature(train_df)\n",
    "y_train = train_df['mode_category']\n",
    "\n",
    "# Step 4: Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Print class distribution after SMOTE\n",
    "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "\n",
    "# Step 6: Separate features and target for validation and test sets\n",
    "X_val = selected_feature(val_df)\n",
    "y_val = val_df['mode_category']\n",
    "\n",
    "X_test = selected_feature(test_df)\n",
    "y_test = test_df['mode_category']\n",
    "\n",
    "# Outputs\n",
    "print(f\"Training set size: {X_train_resampled.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit and predict\n",
    "model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performace of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# print(f\"Accuracy of the Random Forest Classifier: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Perform cross-validation\n",
    "# cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5)\n",
    "\n",
    "# print(f\"Cross-Validated Accuracy: {cv_scores.mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Step 1: Check class distribution\n",
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(\"Class Distribution:\", class_distribution)\n",
    "\n",
    "# Step 2: Generate classification report\n",
    "report = classification_report(y_val, y_pred, target_names=['Active Transportation', 'Auto Driver', 'Auto Passenger', 'Transit'], digits=3)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Step 3: Calculate weighted F1-score\n",
    "weighted_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(\"\\nWeighted F1-Score:\", weighted_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "importances = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 features\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "# Plot the top 10 feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(10))\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

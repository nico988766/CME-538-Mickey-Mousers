{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 3rd party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure Notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the merged dataset of the HH and INDIV datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('Merged_Deliv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step involves extracting the zipcodes from the main dataset and simplifying the cities to which these zipcodes are assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure ZIP codes are in string format to use prefix matching\n",
    "merged_df['HZIP'] = merged_df['HZIP'].astype(str)\n",
    "\n",
    "# Define ZIP code prefixes for California regions\n",
    "zip_prefixes = {\n",
    "    'Los Angeles': ['900', '902', '903', '904', '905', '906', '907', '908'],\n",
    "    'Pasadena': ['910', '911', '912', '913', '914', '915', '916', '917', '918'],\n",
    "    'San Diego': ['919', '920', '921'],\n",
    "    'Riverside': ['922', '923', '925'],\n",
    "    'Orange County': ['926', '927', '928'],\n",
    "    'San Francisco Bay Area': ['940', '941', '943', '944', '945', '946', '947', '948', '949'],\n",
    "    'San Jose': ['950', '951'],\n",
    "    'Stockton': ['952'],\n",
    "    'Sacramento': ['956', '957', '958'],\n",
    "    'Fresno Area': ['936', '937'],\n",
    "    'Ventura and Santa Barbara Area': ['930', '931', '932'],\n",
    "    'Northern California': ['954', '955', '959', '976', '960', '961'],\n",
    "    'California Central Coast': ['934', '939'],\n",
    "    'Central California': ['933', '953'],\n",
    "    'Southern California': ['935'],\n",
    "    'Inland Empire': ['924', '912']\n",
    "}\n",
    "\n",
    "# Define a function to find the matching city\n",
    "def assign_city(zipcode):\n",
    "    for city, prefixes in zip_prefixes.items():\n",
    "        if zipcode[:3] in prefixes:\n",
    "            return city\n",
    "    return None  # If no match, return None\n",
    "\n",
    "# Apply the function to create the 'simplified city' column\n",
    "merged_df['simplified city'] = merged_df['HZIP'].apply(assign_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge weather data onto the dataset, we need a date. Hence, we will merge the ASSN_TravelDate.csv dataset to the main dataset to obtain a temporal feature which can be used as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPN</th>\n",
       "      <th>PERNO</th>\n",
       "      <th>RELAT</th>\n",
       "      <th>GEND</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGEB</th>\n",
       "      <th>HISP</th>\n",
       "      <th>RACE1</th>\n",
       "      <th>RACE2</th>\n",
       "      <th>...</th>\n",
       "      <th>HCTRACT</th>\n",
       "      <th>HPrimaryCity</th>\n",
       "      <th>HSTFIP</th>\n",
       "      <th>MTC_FInalFlag</th>\n",
       "      <th>HHWGT</th>\n",
       "      <th>EXPHHWGT</th>\n",
       "      <th>GPS_MTC</th>\n",
       "      <th>simplified city</th>\n",
       "      <th>TDATE</th>\n",
       "      <th>day_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1046924.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19101</td>\n",
       "      <td>PAUMA VALLEY</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.134283</td>\n",
       "      <td>625.389658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>2012-07-18</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1046924.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19101</td>\n",
       "      <td>PAUMA VALLEY</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.134283</td>\n",
       "      <td>625.389658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>2012-07-18</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1047092.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>427700</td>\n",
       "      <td>ALAMEDA</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.784909</td>\n",
       "      <td>229.994688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>2012-05-05</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1047092.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>427700</td>\n",
       "      <td>ALAMEDA</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.784909</td>\n",
       "      <td>229.994688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>2012-05-05</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1048704.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>MONTCLAIR</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.853113</td>\n",
       "      <td>543.001077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>2012-07-05</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      SAMPN  PERNO  RELAT  GEND   AGE  AGEB  HISP  RACE1  RACE2  ...  \\\n",
       "0   1  1046924.0    1.0    1.0   2.0  77.0   NaN   2.0    1.0    NaN  ...   \n",
       "1   2  1046924.0    2.0    2.0   1.0  77.0   NaN   2.0    1.0    NaN  ...   \n",
       "2   3  1047092.0    1.0    1.0   2.0  50.0   NaN   2.0    1.0    NaN  ...   \n",
       "3   4  1047092.0    2.0    2.0   1.0  51.0   NaN   2.0    1.0    NaN  ...   \n",
       "4   5  1048704.0    1.0    1.0   2.0  36.0   NaN   1.0    1.0    NaN  ...   \n",
       "\n",
       "   HCTRACT  HPrimaryCity HSTFIP  MTC_FInalFlag     HHWGT    EXPHHWGT  GPS_MTC  \\\n",
       "0    19101  PAUMA VALLEY      6            NaN  2.134283  625.389658      NaN   \n",
       "1    19101  PAUMA VALLEY      6            NaN  2.134283  625.389658      NaN   \n",
       "2   427700       ALAMEDA      6            1.0  0.784909  229.994688      NaN   \n",
       "3   427700       ALAMEDA      6            1.0  0.784909  229.994688      NaN   \n",
       "4      207     MONTCLAIR      6            NaN  1.853113  543.001077      NaN   \n",
       "\n",
       "          simplified city      TDATE   day_name  \n",
       "0               San Diego 2012-07-18  Wednesday  \n",
       "1               San Diego 2012-07-18  Wednesday  \n",
       "2  San Francisco Bay Area 2012-05-05   Saturday  \n",
       "3  San Francisco Bay Area 2012-05-05   Saturday  \n",
       "4                Pasadena 2012-07-05   Thursday  \n",
       "\n",
       "[5 rows x 229 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dates = pd.read_csv(\"ASSN_TravelDate.csv\")\n",
    "\n",
    "# Merge the DataFrames on the \"SAMPN\" column\n",
    "merged_df1 = pd.merge(merged_df, df_dates, on=\"ASSN\", how=\"left\")\n",
    "\n",
    "# Convert the date into datetime\n",
    "merged_df1['TDATE'] = pd.to_datetime(merged_df1['TDATE'])\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "merged_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function processes weather data into a format that will allow for its merging to the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather_city(df, city):\n",
    "    \"\"\"\n",
    "    Processes a weather DataFrame by:\n",
    "    1. Converting Unix timestamp to EST and storing in 'TDATE' column.\n",
    "    2. Dropping the original time column.\n",
    "    3. Reordering columns to make 'TDATE' the first column.\n",
    "    4. Adding a 'simplified city' column with the given city name.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame with a 'time' column (Unix time in seconds).\n",
    "    - city (str): The city name to assign to the 'simplified city' column.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert the Unix timestamp to EST and create the 'TDATE' column\n",
    "    def convert_to_est(unix_time):\n",
    "        utc_time = pd.to_datetime(unix_time, unit='s', utc=True)\n",
    "        est_time = utc_time - pd.Timedelta(hours=5)\n",
    "        return est_time\n",
    "\n",
    "    df['TDATE'] = df['time'].apply(convert_to_est)\n",
    "\n",
    "    # Convert 'TDATE' to date-only format and ensure it's datetime\n",
    "    df['TDATE'] = df['TDATE'].dt.date\n",
    "    df['TDATE'] = pd.to_datetime(df['TDATE'])\n",
    "\n",
    "    # Drop the 'time' column\n",
    "    df = df.drop(columns='time')\n",
    "\n",
    "    # Reorder columns to make 'TDATE' the first column\n",
    "    df = df[['TDATE'] + [col for col in df.columns if col != 'TDATE']]\n",
    "\n",
    "    # Add the 'simplified city' column\n",
    "    df['simplified city'] = city\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and prepare the weather data to be merged with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the weather dataset for LA\n",
    "df_LA = pd.read_csv('LA_raw.csv', header=2)\n",
    "df_LA = process_weather_city(df_LA,'Los Angeles')\n",
    "\n",
    "# Prepare the weather dataset for Pasadena\n",
    "df_PA = pd.read_csv('Pasadena_raw.csv', header=2)\n",
    "df_PA = process_weather_city(df_PA,'Pasadena')\n",
    "\n",
    "# Prepare the weather dataset for San Diego\n",
    "df_SD = pd.read_csv('SanDiego_raw.csv', header=2)\n",
    "df_SD = process_weather_city(df_SD,'San Diego')\n",
    "\n",
    "# Prepare the weather dataset for Riverside\n",
    "df_RS = pd.read_csv('Riverside_raw.csv', header=2)\n",
    "df_RS = process_weather_city(df_RS,'Riverside')\n",
    "\n",
    "# Prepare the weather dataset for Orange County\n",
    "df_OC = pd.read_csv('OrangeCounty_raw.csv', header=2)\n",
    "df_OC = process_weather_city(df_OC,'Orange County')\n",
    "\n",
    "# Prepare the weather dataset for San Francisco Bay Area\n",
    "df_SFBA = pd.read_csv('SFBA_raw.csv', header=2)\n",
    "df_SFBA = process_weather_city(df_SFBA,'San Francisco Bay Area')\n",
    "\n",
    "# Prepare the weather dataset for San Jose\n",
    "df_SJ = pd.read_csv('SanJose_raw.csv', header=2)\n",
    "df_SJ = process_weather_city(df_SJ,'San Jose')\n",
    "\n",
    "# Prepare the weather dataset for Stockton\n",
    "df_Stn = pd.read_csv('Stockton_raw.csv', header=2)\n",
    "df_Stn = process_weather_city(df_Stn,'Stockton')\n",
    "\n",
    "# Prepare the weather dataset for Sacramento\n",
    "df_Sc = pd.read_csv('Sacramento_raw.csv', header=2)\n",
    "df_Sc = process_weather_city(df_Sc,'Sacramento')\n",
    "\n",
    "# Prepare the weather dataset for Fresno Area\n",
    "df_FA = pd.read_csv('FresnoArea_raw.csv', header=2)\n",
    "df_FA = process_weather_city(df_FA,'Fresno Area')\n",
    "\n",
    "# Prepare the weather dataset for Ventura and Santa Barbara Area\n",
    "df_VSB = pd.read_csv('VSB_raw.csv', header=2)\n",
    "df_VSB = process_weather_city(df_VSB,'Ventura and Santa Barbara Area')\n",
    "\n",
    "# Prepare the weather dataset for Northern Cali\n",
    "df_NC = pd.read_csv('NC_raw.csv', header=2)\n",
    "df_NC = process_weather_city(df_NC,'Northern California')\n",
    "\n",
    "# Prepare the weather dataset for Cali Central Coast\n",
    "df_CCCo = pd.read_csv('CCCoast_raw.csv', header=2)\n",
    "df_CCCo = process_weather_city(df_CCCo,'California Central Coast')\n",
    "\n",
    "# Prepare the weather dataset for Central Cali\n",
    "df_CC = pd.read_csv('CC_raw.csv', header=2)\n",
    "df_CC = process_weather_city(df_CC,'Central California')\n",
    "\n",
    "# Prepare the weather dataset for Southern Cali\n",
    "df_SouthC = pd.read_csv('SouthC_raw.csv', header=2)\n",
    "df_SouthC = process_weather_city(df_SouthC,'Southern California')\n",
    "\n",
    "# Prepare the weather dataset for Inland Empire\n",
    "df_IE = pd.read_csv('IE_raw.csv', header=2)\n",
    "df_IE = process_weather_city(df_IE,'Inland Empire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to merge the weather data onto the main dataset. The keys used are the cities and the travel date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPN</th>\n",
       "      <th>PERNO</th>\n",
       "      <th>RELAT</th>\n",
       "      <th>GEND</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGEB</th>\n",
       "      <th>HISP</th>\n",
       "      <th>RACE1</th>\n",
       "      <th>RACE2</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_code (wmo code)</th>\n",
       "      <th>temperature_2m_max (Â°C)</th>\n",
       "      <th>temperature_2m_min (Â°C)</th>\n",
       "      <th>temperature_2m_mean (Â°C)</th>\n",
       "      <th>apparent_temperature_mean (Â°C)</th>\n",
       "      <th>daylight_duration (s)</th>\n",
       "      <th>precipitation_sum (mm)</th>\n",
       "      <th>rain_sum (mm)</th>\n",
       "      <th>snowfall_sum (cm)</th>\n",
       "      <th>precipitation_hours (h)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1046924.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>50522.89</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1046924.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>50522.89</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1047092.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>50133.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1047092.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>50133.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1048704.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>51642.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      SAMPN  PERNO  RELAT  GEND   AGE  AGEB  HISP  RACE1  RACE2  ...  \\\n",
       "0   1  1046924.0    1.0    1.0   2.0  77.0   NaN   2.0    1.0    NaN  ...   \n",
       "1   2  1046924.0    2.0    2.0   1.0  77.0   NaN   2.0    1.0    NaN  ...   \n",
       "2   3  1047092.0    1.0    1.0   2.0  50.0   NaN   2.0    1.0    NaN  ...   \n",
       "3   4  1047092.0    2.0    2.0   1.0  51.0   NaN   2.0    1.0    NaN  ...   \n",
       "4   5  1048704.0    1.0    1.0   2.0  36.0   NaN   1.0    1.0    NaN  ...   \n",
       "\n",
       "   weather_code (wmo code)  temperature_2m_max (Â°C) temperature_2m_min (Â°C)  \\\n",
       "0                     51.0                     24.3                    16.2   \n",
       "1                     51.0                     24.3                    16.2   \n",
       "2                      0.0                     22.2                     7.6   \n",
       "3                      0.0                     22.2                     7.6   \n",
       "4                      0.0                     26.1                    13.7   \n",
       "\n",
       "   temperature_2m_mean (Â°C)  apparent_temperature_mean (Â°C)  \\\n",
       "0                      21.0                            21.1   \n",
       "1                      21.0                            21.1   \n",
       "2                      15.2                            12.1   \n",
       "3                      15.2                            12.1   \n",
       "4                      19.6                            20.1   \n",
       "\n",
       "   daylight_duration (s)  precipitation_sum (mm)  rain_sum (mm)  \\\n",
       "0               50522.89                     0.2            0.2   \n",
       "1               50522.89                     0.2            0.2   \n",
       "2               50133.78                     0.0            0.0   \n",
       "3               50133.78                     0.0            0.0   \n",
       "4               51642.60                     0.0            0.0   \n",
       "\n",
       "   snowfall_sum (cm)  precipitation_hours (h)  \n",
       "0                0.0                      1.0  \n",
       "1                0.0                      1.0  \n",
       "2                0.0                      0.0  \n",
       "3                0.0                      0.0  \n",
       "4                0.0                      0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all weather DataFrames\n",
    "weather_df = pd.concat([df_LA, df_PA, df_SD, df_RS, df_OC, df_SFBA, df_SJ, df_Stn, df_Sc, df_FA, df_VSB, df_NC, df_CCCo, df_CC, df_SouthC, df_IE], ignore_index=True)\n",
    "\n",
    "# Merge the main DataFrame with the combined weather DataFrame\n",
    "merged_df_weather = pd.merge(merged_df1, weather_df, on=['simplified city', 'TDATE'], how='left')\n",
    "\n",
    "# View DataFrame\n",
    "merged_df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dataset\n",
    "merged_df_weather.to_csv('merged_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
